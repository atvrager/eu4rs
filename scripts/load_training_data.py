"""Load EU4 training data from Cap'n Proto binary format.

This module provides type-safe loading of training samples generated by the Rust
simulation. It uses pycapnp to read the binary format defined in schemas/training.capnp.

Supports:
  - `.cpb` files: Single Cap'n Proto binary file
  - `.zip` files: ZIP archive containing multiple `.cpb` files (one per year)

Usage:
    from load_training_data import load_training_file, to_huggingface_dataset

    # Load from binary file or ZIP
    samples = load_training_file("training.cpb")
    samples = load_training_file("training.zip")

    # Convert to HuggingFace Dataset
    dataset = to_huggingface_dataset(samples)
"""

from __future__ import annotations

import argparse
import queue
import threading
import zipfile
from collections import Counter
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Iterator

import capnp

# Load the Cap'n Proto schema
# Schema is in ../schemas/training.capnp relative to this file
SCHEMA_PATH = Path(__file__).parent.parent / "schemas" / "training.capnp"
training_capnp = capnp.load(str(SCHEMA_PATH))

# Cap'n Proto traversal limit for large batches
TRAVERSAL_LIMIT = 2**30


def iter_batches_raw(path: Path | str) -> Iterator[Any]:
    """Yield raw Cap'n Proto batch readers without conversion to Python objects.

    This is the fastest way to iterate over training data - access fields
    directly on the reader objects without creating intermediate dataclasses.

    Args:
        path: Path to .cpb file or .zip archive

    Yields:
        Raw Cap'n Proto TrainingBatch reader objects
    """
    path = Path(path)

    if path.suffix.lower() == ".zip":
        with zipfile.ZipFile(path, "r") as zf:
            names = sorted(n for n in zf.namelist() if n.endswith(".cpb"))
            for name in names:
                with zf.open(name) as f:
                    data = f.read()
                    batch = training_capnp.TrainingBatch.from_bytes_packed(
                        data, traversal_limit_in_words=TRAVERSAL_LIMIT
                    )
                    yield batch
    else:
        with open(path, "rb") as f:
            training_file = training_capnp.TrainingFile.read_packed(f)
            for batch in training_file.batches:
                yield batch


def fixed_to_float(reader, scale: int = 1000) -> float:
    """Convert a Fixed Cap'n Proto reader to float without intermediate object."""
    return reader.raw / scale


# Dispatch table for fast command formatting (replaces 40+ if/elif branches)
TECH_MAP = {0: "adm", 1: "dip", 2: "mil"}
DEV_MAP = {0: "tax", 1: "production", 2: "manpower"}

COMMAND_FORMATTERS: dict[str, Any] = {
    # Control
    "pass_": lambda r: "Pass",
    "quit": lambda r: "Quit",
    # Military Movement
    "move": lambda r: f"Move(army={r.move.armyId}, dest={r.move.destination})",
    "moveFleet": lambda r: f"MoveFleet(fleet={r.moveFleet.fleetId}, dest={r.moveFleet.destination})",
    "embark": lambda r: f"Embark(army={r.embark.armyId}, fleet={r.embark.fleetId})",
    "disembark": lambda r: f"Disembark(army={r.disembark.armyId}, dest={r.disembark.destination})",
    "mergeArmies": lambda r: f"MergeArmies({list(r.mergeArmies)})",
    "splitArmy": lambda r: f"SplitArmy(army={r.splitArmy.armyId}, count={r.splitArmy.regimentCount})",
    # War & Peace
    "declareWar": lambda r: f"DeclareWar(target={r.declareWar.target}, cb={r.declareWar.cb})",
    "offerPeace": lambda r: f"OfferPeace(war={r.offerPeace.warId})",
    "acceptPeace": lambda r: f"AcceptPeace(war={r.acceptPeace})",
    "rejectPeace": lambda r: f"RejectPeace(war={r.rejectPeace})",
    # Tech & Institutions
    "buyTech": lambda r: f"BuyTech({TECH_MAP.get(r.buyTech, r.buyTech)})",
    "embraceInstitution": lambda r: f"EmbraceInstitution({r.embraceInstitution})",
    # Economic
    "buildInProvince": lambda r: f"Build(prov={r.buildInProvince.province}, building={r.buildInProvince.building})",
    "developProvince": lambda r: f"Develop(prov={r.developProvince.province}, type={DEV_MAP.get(r.developProvince.devType, r.developProvince.devType)})",
    # Colonization
    "startColony": lambda r: f"StartColony(prov={r.startColony})",
    "abandonColony": lambda r: f"AbandonColony(prov={r.abandonColony})",
    # Diplomacy - Outgoing
    "offerAlliance": lambda r: f"OfferAlliance({r.offerAlliance})",
    "breakAlliance": lambda r: f"BreakAlliance({r.breakAlliance})",
    "offerRoyalMarriage": lambda r: f"OfferRoyalMarriage({r.offerRoyalMarriage})",
    "breakRoyalMarriage": lambda r: f"BreakRoyalMarriage({r.breakRoyalMarriage})",
    "requestMilitaryAccess": lambda r: f"RequestMilitaryAccess({r.requestMilitaryAccess})",
    "cancelMilitaryAccess": lambda r: f"CancelMilitaryAccess({r.cancelMilitaryAccess})",
    "setRival": lambda r: f"SetRival({r.setRival})",
    "removeRival": lambda r: f"RemoveRival({r.removeRival})",
    # Diplomacy - Responses
    "acceptAlliance": lambda r: f"AcceptAlliance({r.acceptAlliance})",
    "rejectAlliance": lambda r: f"RejectAlliance({r.rejectAlliance})",
    "acceptRoyalMarriage": lambda r: f"AcceptRoyalMarriage({r.acceptRoyalMarriage})",
    "rejectRoyalMarriage": lambda r: f"RejectRoyalMarriage({r.rejectRoyalMarriage})",
    "grantMilitaryAccess": lambda r: f"GrantMilitaryAccess({r.grantMilitaryAccess})",
    "denyMilitaryAccess": lambda r: f"DenyMilitaryAccess({r.denyMilitaryAccess})",
    # Religion
    "assignMissionary": lambda r: f"AssignMissionary(prov={r.assignMissionary})",
    "recallMissionary": lambda r: f"RecallMissionary(prov={r.recallMissionary})",
    "convertCountryReligion": lambda r: f"ConvertReligion({r.convertCountryReligion})",
    # Control
    "moveCapital": lambda r: f"MoveCapital(prov={r.moveCapital})",
}


def command_to_string_fast(cmd_reader) -> str:
    """Convert a Cap'n Proto Command to string using dispatch table (faster)."""
    which = cmd_reader.which()
    formatter = COMMAND_FORMATTERS.get(which)
    if formatter:
        return formatter(cmd_reader)
    return f"Unknown({which})"


@dataclass
class Date:
    """Game date (year/month/day)."""

    year: int
    month: int
    day: int

    @classmethod
    def from_capnp(cls, reader) -> "Date":
        return cls(year=reader.year, month=reader.month, day=reader.day)

    def __str__(self) -> str:
        return f"{self.year}.{self.month}.{self.day}"


@dataclass
class Fixed:
    """Fixed-point number (raw i64 value)."""

    raw: int

    @classmethod
    def from_capnp(cls, reader) -> "Fixed":
        return cls(raw=reader.raw)

    def to_float(self, scale: int = 1000) -> float:
        """Convert to float with given scale (default 1000 = 3 decimal places)."""
        return self.raw / scale


@dataclass
class CountryState:
    """Visible state of a country."""

    treasury: float
    manpower: float
    stability: int
    prestige: float
    army_tradition: float
    adm_mana: float
    dip_mana: float
    mil_mana: float
    adm_tech: int
    dip_tech: int
    mil_tech: int
    embraced_institutions: list[str]
    religion: str

    @classmethod
    def from_capnp(cls, reader) -> "CountryState":
        return cls(
            treasury=Fixed.from_capnp(reader.treasury).to_float(),
            manpower=Fixed.from_capnp(reader.manpower).to_float(),
            stability=reader.stability,
            prestige=Fixed.from_capnp(reader.prestige).to_float(),
            army_tradition=Fixed.from_capnp(reader.armyTradition).to_float(),
            adm_mana=Fixed.from_capnp(reader.admMana).to_float(),
            dip_mana=Fixed.from_capnp(reader.dipMana).to_float(),
            mil_mana=Fixed.from_capnp(reader.milMana).to_float(),
            adm_tech=reader.admTech,
            dip_tech=reader.dipTech,
            mil_tech=reader.milTech,
            embraced_institutions=list(reader.embracedInstitutions),
            religion=reader.religion,
        )


@dataclass
class VisibleWorldState:
    """The visible world state from a country's perspective."""

    date: Date
    observer: str
    own_country: CountryState
    at_war: bool
    known_countries: list[str]
    enemy_provinces: list[int]
    known_country_strength: dict[str, int]
    our_war_score: dict[int, float]

    @classmethod
    def from_capnp(cls, reader) -> "VisibleWorldState":
        # Convert list of entries to dict
        strength = {e.country: e.strength for e in reader.knownCountryStrength}
        war_score = {
            e.warId: Fixed.from_capnp(e.score).to_float() for e in reader.ourWarScore
        }

        return cls(
            date=Date.from_capnp(reader.date),
            observer=reader.observer,
            own_country=CountryState.from_capnp(reader.ownCountry),
            at_war=reader.atWar,
            known_countries=list(reader.knownCountries),
            enemy_provinces=list(reader.enemyProvinces),
            known_country_strength=strength,
            our_war_score=war_score,
        )


def command_to_string(cmd_reader) -> str:
    """Convert a Cap'n Proto Command to a human-readable string.

    Matches the schema in schemas/training.capnp.
    """
    which = cmd_reader.which()

    # Control commands
    if which == "pass_":
        return "Pass"
    elif which == "quit":
        return "Quit"

    # Military Movement (groups)
    elif which == "move":
        return (
            f"Move(army={cmd_reader.move.armyId}, dest={cmd_reader.move.destination})"
        )
    elif which == "moveFleet":
        return f"MoveFleet(fleet={cmd_reader.moveFleet.fleetId}, dest={cmd_reader.moveFleet.destination})"
    elif which == "embark":
        return f"Embark(army={cmd_reader.embark.armyId}, fleet={cmd_reader.embark.fleetId})"
    elif which == "disembark":
        return f"Disembark(army={cmd_reader.disembark.armyId}, dest={cmd_reader.disembark.destination})"
    elif which == "mergeArmies":
        return f"MergeArmies({list(cmd_reader.mergeArmies)})"
    elif which == "splitArmy":
        return f"SplitArmy(army={cmd_reader.splitArmy.armyId}, count={cmd_reader.splitArmy.regimentCount})"

    # War & Peace
    elif which == "declareWar":
        return f"DeclareWar(target={cmd_reader.declareWar.target}, cb={cmd_reader.declareWar.cb})"
    elif which == "offerPeace":
        return f"OfferPeace(war={cmd_reader.offerPeace.warId})"
    elif which == "acceptPeace":
        return f"AcceptPeace(war={cmd_reader.acceptPeace})"
    elif which == "rejectPeace":
        return f"RejectPeace(war={cmd_reader.rejectPeace})"

    # Tech & Institutions (plain values)
    elif which == "buyTech":
        tech_map = {0: "adm", 1: "dip", 2: "mil"}
        return f"BuyTech({tech_map.get(cmd_reader.buyTech, cmd_reader.buyTech)})"
    elif which == "embraceInstitution":
        return f"EmbraceInstitution({cmd_reader.embraceInstitution})"

    # Economic (groups)
    elif which == "buildInProvince":
        return f"Build(prov={cmd_reader.buildInProvince.province}, building={cmd_reader.buildInProvince.building})"
    elif which == "developProvince":
        dev = cmd_reader.developProvince
        dev_map = {0: "tax", 1: "production", 2: "manpower"}
        return f"Develop(prov={dev.province}, type={dev_map.get(dev.devType, dev.devType)})"

    # Colonization (plain province IDs)
    elif which == "startColony":
        return f"StartColony(prov={cmd_reader.startColony})"
    elif which == "abandonColony":
        return f"AbandonColony(prov={cmd_reader.abandonColony})"

    # Diplomacy - Outgoing (plain country tags)
    elif which == "offerAlliance":
        return f"OfferAlliance({cmd_reader.offerAlliance})"
    elif which == "breakAlliance":
        return f"BreakAlliance({cmd_reader.breakAlliance})"
    elif which == "offerRoyalMarriage":
        return f"OfferRoyalMarriage({cmd_reader.offerRoyalMarriage})"
    elif which == "breakRoyalMarriage":
        return f"BreakRoyalMarriage({cmd_reader.breakRoyalMarriage})"
    elif which == "requestMilitaryAccess":
        return f"RequestMilitaryAccess({cmd_reader.requestMilitaryAccess})"
    elif which == "cancelMilitaryAccess":
        return f"CancelMilitaryAccess({cmd_reader.cancelMilitaryAccess})"
    elif which == "setRival":
        return f"SetRival({cmd_reader.setRival})"
    elif which == "removeRival":
        return f"RemoveRival({cmd_reader.removeRival})"

    # Diplomacy - Responses (plain country tags)
    elif which == "acceptAlliance":
        return f"AcceptAlliance({cmd_reader.acceptAlliance})"
    elif which == "rejectAlliance":
        return f"RejectAlliance({cmd_reader.rejectAlliance})"
    elif which == "acceptRoyalMarriage":
        return f"AcceptRoyalMarriage({cmd_reader.acceptRoyalMarriage})"
    elif which == "rejectRoyalMarriage":
        return f"RejectRoyalMarriage({cmd_reader.rejectRoyalMarriage})"
    elif which == "grantMilitaryAccess":
        return f"GrantMilitaryAccess({cmd_reader.grantMilitaryAccess})"
    elif which == "denyMilitaryAccess":
        return f"DenyMilitaryAccess({cmd_reader.denyMilitaryAccess})"

    # Religion (plain province IDs or country tags)
    elif which == "assignMissionary":
        return f"AssignMissionary(prov={cmd_reader.assignMissionary})"
    elif which == "recallMissionary":
        return f"RecallMissionary(prov={cmd_reader.recallMissionary})"
    elif which == "convertCountryReligion":
        return f"ConvertReligion({cmd_reader.convertCountryReligion})"

    # Control
    elif which == "moveCapital":
        return f"MoveCapital(prov={cmd_reader.moveCapital})"

    else:
        return f"Unknown({which})"


@dataclass
class TrainingSample:
    """A single training sample for ML.

    Multi-command support: AI can submit multiple commands per tick.
    - chosen_actions: List of indices into available_commands
    - chosen_commands: List of command strings
    Empty lists mean "Pass" (no action taken).
    """

    tick: int
    country: str
    state: VisibleWorldState
    available_commands: list[str]
    chosen_actions: list[int]
    chosen_commands: list[str]

    @classmethod
    def from_capnp(cls, reader) -> "TrainingSample":
        available = [command_to_string(cmd) for cmd in reader.availableCommands]
        actions = list(reader.chosenActions)
        commands = [command_to_string(cmd) for cmd in reader.chosenCommands]

        return cls(
            tick=reader.tick,
            country=reader.country,
            state=VisibleWorldState.from_capnp(reader.state),
            available_commands=available,
            chosen_actions=actions,
            chosen_commands=commands,
        )

    def to_prompt(self) -> str:
        """Format this sample as a training prompt."""
        state = self.state
        date = state.date
        country = state.own_country

        lines = [
            f"Date: {date}",
            f"Country: {state.observer}",
            f"Treasury: {country.treasury:.1f}",
            f"Manpower: {country.manpower:.1f}",
            f"Stability: {country.stability}",
            f"Prestige: {country.prestige:.1f}",
            f"Tech: ADM {country.adm_tech} / DIP {country.dip_tech} / MIL {country.mil_tech}",
            f"Mana: ADM {country.adm_mana:.0f} / DIP {country.dip_mana:.0f} / MIL {country.mil_mana:.0f}",
            f"At War: {'Yes' if state.at_war else 'No'}",
            "",
            "Available Actions:",
        ]

        for i, cmd in enumerate(self.available_commands):
            lines.append(f"  [{i}] {cmd}")

        return "\n".join(lines)

    def to_completion(self) -> str:
        """Format the chosen actions as a completion.

        Multi-command format: each action on its own line.
        """
        if not self.chosen_commands:
            return "Action: Pass"

        lines = []
        for idx, cmd in zip(self.chosen_actions, self.chosen_commands):
            lines.append(f"Action: [{idx}] {cmd}")
        return "\n".join(lines)


def load_training_file(path: Path | str) -> list[TrainingSample]:
    """Load all training samples from a Cap'n Proto file or ZIP archive.

    Supports:
      - `.cpb` files: Direct Cap'n Proto binary (TrainingFile message)
      - `.zip` files: ZIP archive with `.cpb` files inside (one TrainingBatch per file)

    Args:
        path: Path to .cpb file or .zip archive

    Returns:
        List of TrainingSample objects
    """
    path = Path(path)
    samples = []

    if path.suffix.lower() == ".zip":
        # ZIP archive containing .cpb files
        with zipfile.ZipFile(path, "r") as zf:
            # Sort for deterministic ordering
            names = sorted(n for n in zf.namelist() if n.endswith(".cpb"))
            for name in names:
                with zf.open(name) as f:
                    data = f.read()
                    # Use high traversal limit for large yearly batches (~500MB each)
                    batch = training_capnp.TrainingBatch.from_bytes_packed(
                        data, traversal_limit_in_words=2**30
                    )
                    for sample in batch.samples:
                        samples.append(TrainingSample.from_capnp(sample))
    else:
        # Single .cpb file (TrainingFile format)
        with open(path, "rb") as f:
            training_file = training_capnp.TrainingFile.read_packed(f)
            for batch in training_file.batches:
                for sample in batch.samples:
                    samples.append(TrainingSample.from_capnp(sample))

    return samples


def iter_training_file(path: Path | str) -> Iterator[TrainingSample]:
    """Iterate over training samples from a Cap'n Proto file or ZIP archive.

    Memory-efficient streaming version of load_training_file.

    Args:
        path: Path to .cpb file or .zip archive

    Yields:
        TrainingSample objects
    """
    path = Path(path)

    if path.suffix.lower() == ".zip":
        with zipfile.ZipFile(path, "r") as zf:
            names = sorted(n for n in zf.namelist() if n.endswith(".cpb"))
            for name in names:
                with zf.open(name) as f:
                    data = f.read()
                    # Use high traversal limit for large yearly batches
                    batch = training_capnp.TrainingBatch.from_bytes_packed(
                        data, traversal_limit_in_words=2**30
                    )
                    for sample in batch.samples:
                        yield TrainingSample.from_capnp(sample)
    else:
        with open(path, "rb") as f:
            training_file = training_capnp.TrainingFile.read_packed(f)
            for batch in training_file.batches:
                for sample in batch.samples:
                    yield TrainingSample.from_capnp(sample)


def compute_stats_streaming(path: Path | str) -> dict:
    """Compute statistics directly from Cap'n Proto readers without materialization.

    This is 10-50x faster than loading all samples into Python dataclasses first.

    Args:
        path: Path to .cpb file or .zip archive

    Returns:
        Dictionary with 'total', 'countries', 'actions', 'min_tick', 'max_tick'
    """
    countries: Counter[str] = Counter()
    actions: Counter[int] = Counter()
    min_tick = float("inf")
    max_tick = 0
    total = 0

    for batch in iter_batches_raw(path):
        for sample in batch.samples:
            # Access reader fields directly - no dataclass creation!
            total += 1
            countries[sample.country] += 1
            actions[sample.chosenAction] += 1
            tick = sample.tick
            if tick < min_tick:
                min_tick = tick
            if tick > max_tick:
                max_tick = tick

    return {
        "total": total,
        "countries": dict(countries),
        "actions": dict(actions),
        "min_tick": int(min_tick) if total > 0 else 0,
        "max_tick": max_tick,
    }


def print_stats_from_dict(stats: dict) -> None:
    """Print statistics from a stats dictionary."""
    if stats["total"] == 0:
        print("No samples found.")
        return

    print(f"Total samples: {stats['total']}")
    print(f"Tick range: {stats['min_tick']} - {stats['max_tick']}")
    print(
        f"Year range: {1444 + stats['min_tick'] // 365} - {1444 + stats['max_tick'] // 365}"
    )
    print()
    print("Top countries:")
    for country, count in sorted(stats["countries"].items(), key=lambda x: -x[1])[:10]:
        print(f"  {country}: {count}")
    print()
    print("Action distribution:")
    for action, count in sorted(stats["actions"].items()):
        pct = count / stats["total"] * 100
        label = "Pass" if action == -1 else f"Action[{action}]"
        print(f"  {label}: {count} ({pct:.1f}%)")


def format_prompt_from_reader(sample_reader) -> str:
    """Format a training prompt directly from a Cap'n Proto reader.

    Avoids creating intermediate Python dataclasses for better performance.
    """
    state = sample_reader.state
    date = state.date
    country = state.ownCountry

    lines = [
        f"Date: {date.year}.{date.month}.{date.day}",
        f"Country: {state.observer}",
        f"Treasury: {fixed_to_float(country.treasury):.1f}",
        f"Manpower: {fixed_to_float(country.manpower):.1f}",
        f"Stability: {country.stability}",
        f"Prestige: {fixed_to_float(country.prestige):.1f}",
        f"Tech: ADM {country.admTech} / DIP {country.dipTech} / MIL {country.milTech}",
        f"Mana: ADM {fixed_to_float(country.admMana):.0f} / DIP {fixed_to_float(country.dipMana):.0f} / MIL {fixed_to_float(country.milMana):.0f}",
        f"At War: {'Yes' if state.atWar else 'No'}",
        "",
        "Available Actions:",
    ]

    for i, cmd in enumerate(sample_reader.availableCommands):
        lines.append(f"  [{i}] {command_to_string_fast(cmd)}")

    return "\n".join(lines)


def format_completion_from_reader(sample_reader) -> str:
    """Format a training completion directly from a Cap'n Proto reader."""
    chosen_action = sample_reader.chosenAction
    if chosen_action >= 0:
        chosen_cmd = command_to_string_fast(sample_reader.chosenCommand)
        return f"Action: [{chosen_action}] {chosen_cmd}"
    else:
        return f"Action: [{chosen_action}] Pass"


def iter_training_prompts(path: Path | str) -> Iterator[dict]:
    """Stream prompt/completion pairs directly from Cap'n Proto readers.

    This is the most memory-efficient way to feed training data to HuggingFace.
    No intermediate Python dataclasses are created.

    Args:
        path: Path to .cpb file or .zip archive

    Yields:
        Dictionaries with 'text', 'country', 'tick' keys
    """
    for batch in iter_batches_raw(path):
        for sample in batch.samples:
            prompt = format_prompt_from_reader(sample)
            completion = format_completion_from_reader(sample)
            yield {
                "text": f"{prompt}\n{completion}",
                "country": sample.country,
                "tick": sample.tick,
            }


def to_huggingface_dataset(samples: list[TrainingSample]):
    """Convert training samples to a HuggingFace Dataset.

    Args:
        samples: List of TrainingSample objects

    Returns:
        datasets.Dataset with 'prompt' and 'completion' columns
    """
    from datasets import Dataset

    data = {"prompt": [], "completion": [], "country": [], "tick": []}

    for sample in samples:
        data["prompt"].append(sample.to_prompt())
        data["completion"].append(sample.to_completion())
        data["country"].append(sample.country)
        data["tick"].append(sample.tick)

    return Dataset.from_dict(data)


def _training_prompts_generator(path_str: str) -> Iterator[dict]:
    """Generator function for HuggingFace streaming - takes path as string param."""
    yield from iter_training_prompts(path_str)


def to_huggingface_dataset_streaming(path: Path | str):
    """Create a streaming HuggingFace IterableDataset from training data.

    This is the recommended way to load large training datasets. It starts
    immediately without loading everything into memory first.

    Args:
        path: Path to .cpb file or .zip archive

    Returns:
        IterableDataset ready for training
    """
    from datasets import IterableDataset

    # Pass path as gen_kwargs to avoid pickling issues with closures
    path_str = str(Path(path).resolve())
    return IterableDataset.from_generator(
        _training_prompts_generator,
        gen_kwargs={"path_str": path_str},
    )


def to_huggingface_dataset_chunked(path: Path | str, chunk_size: int = 50000):
    """Create a chunked HuggingFace Dataset that loads in batches.

    This is the best balance between eager (fast but slow startup) and
    streaming (slow but immediate startup). It loads chunks of samples
    and yields them, allowing training to start faster than eager mode.

    Args:
        path: Path to .cpb file or .zip archive
        chunk_size: Number of samples per chunk (default: 50000)

    Returns:
        IterableDataset ready for training
    """
    from datasets import IterableDataset

    # Pass params via gen_kwargs to avoid pickle issues with closures
    path_str = str(Path(path).resolve())
    return IterableDataset.from_generator(
        _chunked_prompts_generator,
        gen_kwargs={"path_str": path_str, "chunk_size": chunk_size},
    )


def _chunked_prompts_generator(path_str: str, chunk_size: int) -> Iterator[dict]:
    """Top-level generator for chunked loading (avoids pickle issues).

    Loads samples in chunks and yields them. The chunking reduces memory
    pressure compared to full eager loading while still being faster than
    pure streaming because we process batches at a time.
    """
    path = Path(path_str)
    chunk = []

    for batch in iter_batches_raw(path):
        for sample in batch.samples:
            prompt = format_prompt_from_reader(sample)
            completion = format_completion_from_reader(sample)
            chunk.append(
                {
                    "text": f"{prompt}\n{completion}",
                    "country": sample.country,
                    "tick": sample.tick,
                }
            )

            # When chunk is full, yield all samples and clear
            if len(chunk) >= chunk_size:
                for item in chunk:
                    yield item
                chunk = []

    # Yield remaining samples
    for item in chunk:
        yield item


def _iter_all_samples_raw(path: Path):
    """Iterate over all raw sample readers from a path."""
    for batch in iter_batches_raw(path):
        for sample in batch.samples:
            yield sample


class _PrefetchManager:
    """Manages background prefetch thread for training data.

    Starts a producer thread that fills a queue while the consumer
    (trainer) pulls from it. This overlaps CPU-bound data loading
    with GPU-bound training.
    """

    def __init__(self, path: Path, prefetch_count: int):
        self.path = path
        self.prefetch_count = prefetch_count
        self._queue: queue.Queue = queue.Queue(maxsize=prefetch_count)
        self._stop_event = threading.Event()
        self._producer: threading.Thread | None = None
        self._exception: Exception | None = None
        self._started = False

    def _producer_fn(self):
        """Background thread: load samples and push to queue."""
        try:
            for batch in iter_batches_raw(self.path):
                for sample in batch.samples:
                    if self._stop_event.is_set():
                        return
                    prompt = format_prompt_from_reader(sample)
                    completion = format_completion_from_reader(sample)
                    item = {
                        "text": f"{prompt}\n{completion}",
                        "country": sample.country,
                        "tick": sample.tick,
                    }
                    self._queue.put(item)
        except Exception as e:
            self._exception = e
        finally:
            self._queue.put(None)

    def start(self):
        """Start the prefetch producer thread."""
        if self._started:
            return
        self._started = True
        self._stop_event.clear()
        self._producer = threading.Thread(target=self._producer_fn, daemon=True)
        self._producer.start()

    def get_item(self):
        """Get next item from queue. Returns None when exhausted."""
        item = self._queue.get()
        if item is None and self._exception:
            raise self._exception
        return item

    def stop(self):
        """Signal producer to stop."""
        self._stop_event.set()


# Global prefetch manager - survives generator recreation by HuggingFace
_prefetch_managers: dict[str, _PrefetchManager] = {}


def _prefetch_generator(path_str: str, prefetch_count: int) -> Iterator[dict]:
    """Generator that pulls from prefetch queue.

    Uses a global manager so the producer thread survives HuggingFace's
    generator recreation during .map() calls.
    """
    global _prefetch_managers

    # Get or create manager for this path
    key = f"{path_str}:{prefetch_count}"
    if key not in _prefetch_managers:
        _prefetch_managers[key] = _PrefetchManager(Path(path_str), prefetch_count)

    manager = _prefetch_managers[key]
    manager.start()

    # Pull from queue until exhausted
    while True:
        item = manager.get_item()
        if item is None:
            del _prefetch_managers[key]
            break
        yield item


def to_huggingface_dataset_prefetch(path: Path | str, prefetch_count: int = 1000):
    """Create a HuggingFace IterableDataset with true background prefetching.

    Uses a producer-consumer pattern: a background thread loads and formats
    samples while the main thread (trainer) consumes them. This overlaps
    CPU-bound data loading with GPU-bound training.

    Args:
        path: Path to .cpb file or .zip archive
        prefetch_count: Max items to buffer in queue (default: 1000)

    Returns:
        HuggingFace IterableDataset ready for training
    """
    from datasets import IterableDataset

    path_str = str(Path(path).resolve())
    return IterableDataset.from_generator(
        _prefetch_generator,
        gen_kwargs={"path_str": path_str, "prefetch_count": prefetch_count},
    )


def print_sample_stats(samples: list[TrainingSample]) -> None:
    """Print statistics about loaded samples."""
    if not samples:
        print("No samples loaded.")
        return

    countries = {}
    actions = {}
    min_tick = samples[0].tick
    max_tick = samples[0].tick

    for s in samples:
        countries[s.country] = countries.get(s.country, 0) + 1
        actions[s.chosen_action] = actions.get(s.chosen_action, 0) + 1
        min_tick = min(min_tick, s.tick)
        max_tick = max(max_tick, s.tick)

    print(f"Total samples: {len(samples)}")
    print(f"Tick range: {min_tick} - {max_tick}")
    print(f"Year range: {1444 + min_tick // 365} - {1444 + max_tick // 365}")
    print()
    print("Top countries:")
    for country, count in sorted(countries.items(), key=lambda x: -x[1])[:10]:
        print(f"  {country}: {count}")
    print()
    print("Action distribution:")
    for action, count in sorted(actions.items()):
        pct = count / len(samples) * 100
        label = "Pass" if action == -1 else f"Action[{action}]"
        print(f"  {label}: {count} ({pct:.1f}%)")


def main():
    """CLI entry point for inspecting training data."""
    parser = argparse.ArgumentParser(
        description="Load and inspect Cap'n Proto training data"
    )
    parser.add_argument(
        "path", type=Path, help="Path to .cpb file or .zip archive of .cpb files"
    )
    parser.add_argument("--stats", "-s", action="store_true", help="Show statistics")
    parser.add_argument(
        "--samples", "-n", type=int, default=0, help="Show N sample prompts"
    )
    parser.add_argument("--country", "-c", type=str, help="Filter by country tag")
    parser.add_argument(
        "--eager",
        action="store_true",
        help="Force eager loading (slower, for debugging)",
    )

    args = parser.parse_args()

    if not args.path.exists():
        print(f"Error: File not found: {args.path}")
        return 1

    # Fast path: streaming mode (default unless --eager or --country filter)
    use_streaming = not args.eager and not args.country

    if use_streaming:
        if args.stats:
            print(f"Computing stats (streaming) for {args.path}...")
            stats = compute_stats_streaming(args.path)
            print_stats_from_dict(stats)

        if args.samples > 0:
            print(f"\n=== First {args.samples} samples (streaming) ===\n")
            count = 0
            for sample_dict in iter_training_prompts(args.path):
                if count >= args.samples:
                    break
                print("-" * 60)
                print(sample_dict["text"])
                print()
                count += 1

        return 0

    # Slow path: full loading (only for --eager or --country filter)
    print(f"Loading {args.path} (eager mode)...")
    samples = load_training_file(args.path)

    if args.country:
        samples = [s for s in samples if s.country == args.country]
        print(f"Filtered to {len(samples)} samples for {args.country}")

    if args.stats:
        print_sample_stats(samples)

    if args.samples > 0:
        print(f"\n=== First {min(args.samples, len(samples))} samples ===\n")
        for sample in samples[: args.samples]:
            print("-" * 60)
            print(sample.to_prompt())
            print()
            print(sample.to_completion())
            print()

    return 0


if __name__ == "__main__":
    exit(main())
